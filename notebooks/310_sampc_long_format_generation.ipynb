{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/zuster_fietje/notebooks/300_zuster_fietje/310_sampc_long_format_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "!pip -q install datasets\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 6\n",
        "# Path for pushing dataset to HuggingFace Hub\n",
        "path_hf_sampc_long = \"ekrombouts/Galaxy_SAMPC_long\"\n",
        "# Commit message for the push\n",
        "commit_message = \"Galaxy_SAMPC dataset to long format\""
      ],
      "metadata": {
        "id": "TyE987Kiwibl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from HuggingFace\n",
        "dataset = load_dataset(\"ekrombouts/Galaxy_SAMPC\")\n",
        "\n",
        "# Combine train, test, and validation splits into a single DataFrame\n",
        "df = pd.concat([dataset['train'].to_pandas(),\n",
        "                dataset['test'].to_pandas(),\n",
        "                dataset['validation'].to_pandas()],\n",
        "                ignore_index=True)"
      ],
      "metadata": {
        "id": "Zw0ChSRanSwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate prompts for different categories\n",
        "def generate_prompts(df):\n",
        "    rows = []\n",
        "    for idx, row in df.iterrows():\n",
        "        notes = row['notes']\n",
        "        prompts = {\n",
        "            'somatiek': f\"Lees de volgende rapportages en beschrijf de lichamelijke klachten van de cliënt.\\n\\nRapportages:\\n{notes}\\n\\nGeef de output als lijst van strings: ['foo', 'bar'].\\n\\nBeschrijf de lichamelijke klachten:\",\n",
        "            'adl': f\"Lees de volgende rapportages en beschrijf welke hulp de cliënt nodig heeft bij wassen en kleden.\\n\\nRapportages:\\n{notes}\\n\\nBeschrijf de hulp bij wassen en kleden:\",\n",
        "            'mobiliteit': f\"Lees de volgende rapportages en beschrijf de mobiliteit van de cliënt.\\n\\nRapportages:\\n{notes}\\n\\nBeschrijf de mobiliteit van de cliënt:\",\n",
        "            'continentie': f\"Lees de volgende rapportages en beschrijf de continentie van de cliënt.\\n\\nRapportages:\\n{notes}\\n\\nBeschrijf de continentie van de cliënt:\",\n",
        "            'maatschappelijk': f\"Lees de volgende rapportages en beschrijf bijzonderheden rondom familie en dagbesteding van de cliënt.\\n\\nRapportages:\\n{notes}\\n\\nBeschrijf de familie en dagbesteding:\",\n",
        "            'psychisch': f\"Lees de volgende rapportages en beschrijf de cognitie en gedragsproblemen van de cliënt.\\n\\nRapportages:\\n{notes}\\n\\nGeef de output als lijst van strings: ['foo', 'bar'].\\n\\nBeschrijf cognitie en gedragsproblemen:\"\n",
        "        }\n",
        "\n",
        "        for category, prompt in prompts.items():\n",
        "            rows.append({'notes': row['notes'], 'prompt': prompt, 'reference': row[category], 'category': category})\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "Okhe5CGbnWjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate prompts and create a new DataFrame\n",
        "df_prompts = generate_prompts(df)\n",
        "\n",
        "# Convert the 'reference' column to string type\n",
        "df_prompts['reference'] = df_prompts['reference'].astype(str)"
      ],
      "metadata": {
        "id": "LW709Hhv_Sf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the DataFrame to a HuggingFace Dataset object\n",
        "dataset = Dataset.from_pandas(df_prompts)\n",
        "\n",
        "# Split the dataset into training and test/validation splits\n",
        "train_testvalid_split = dataset.train_test_split(test_size=0.2, seed=seed)\n",
        "\n",
        "# Further split the test set into validation and test sets\n",
        "test_valid_split = train_testvalid_split['test'].train_test_split(test_size=0.5, seed=seed)\n",
        "\n",
        "# Create a DatasetDict object to hold the splits\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_testvalid_split['train'],\n",
        "    'validation': test_valid_split['train'],\n",
        "    'test': test_valid_split['test'],\n",
        "})\n",
        "\n",
        "# Push the dataset to HuggingFace Hub with the specified path and commit message\n",
        "dataset_dict.push_to_hub(path_hf_sampc_long,\n",
        "                         commit_message=commit_message,\n",
        "                         private=True)"
      ],
      "metadata": {
        "id": "dawJPW_ZvFnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQV7xK3RpzmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}