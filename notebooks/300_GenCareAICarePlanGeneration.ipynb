{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ekrombouts/gcai_zuster_fietje/blob/main/notebooks/300_GenCareAICarePlanGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwx-li06oX8C"
   },
   "source": [
    "## Creating a Careplan Dataset from GenCareAI Client records\n",
    "\n",
    "**Author:** Eva Rombouts  \n",
    "**Date:** 2024-09-16  \n",
    "**Updated:** 2024-11-30\n",
    "\n",
    "### Description\n",
    "This notebook summarizes nursing home client notes into the Careplan format using OpenAI’s GPT model via LangChain. It processes the data, generates careplans, and prepares the dataset by splitting it into training, validation, and test sets, and uploads it to the Hugging Face Hub for use in machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIddGTJcE7Hf"
   },
   "source": [
    "## Environment Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufty-17OFS0H",
    "outputId": "5465e535-5ba6-45bc-af3b-d394515db93e"
   },
   "outputs": [],
   "source": [
    "# # When in Colab\n",
    "# from google.colab import drive, userdata\n",
    "# import os\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# base_dir = \"/content/drive/My Drive/Colab Notebooks/GenCareAI\"\n",
    "# open_ai_api_key = userdata.get(\"GCI_OPENAI_API_KEY\")\n",
    "\n",
    "# !pip install -q datasets langchain langchain_community langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When in local\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(os.getcwd()).resolve().parents[0]\n",
    "open_ai_api_key = os.getenv(\"GCI_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OOrSISU7r15"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from datasets import load_dataset, Dataset, DatasetDict  # For loading and managing datasets\n",
    "from typing import List\n",
    "\n",
    "# Langchain modules\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "# Pydantic library for data validation\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# OpenAI API integration using langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Scikit-learn library for splitting datasets into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQEKWDLNv1QJ"
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "seed = 6\n",
    "\n",
    "# Data paths\n",
    "nursing_care_home_name = \"Gardenia\"\n",
    "# For reading data\n",
    "path_hf_records = f\"ekrombouts/{nursing_care_home_name}_records\"\n",
    "path_hf_clients = f\"ekrombouts/{nursing_care_home_name}_clients\"\n",
    "\n",
    "# For writing data\n",
    "path_hf_careplan = f\"ekrombouts/{nursing_care_home_name}_Careplan_dataset\"\n",
    "commit_message = \"Careplan dataset. Created: https://colab.research.google.com/github/ekrombouts/gcai_zuster_fietje/blob/main/notebooks/300_GenCareAICarePlanGeneration.ipynb\"\n",
    "\n",
    "# File path for saving the generated Careplans\n",
    "fn_responses = os.path.join(base_dir, f\"data/care_pal/{nursing_care_home_name}_Careplan_dataset.pkl\")\n",
    "\n",
    "# Settings for Careplan generation\n",
    "model = \"gpt-4o-mini-2024-07-18\"\n",
    "temperature = 0.3\n",
    "\n",
    "sep_line = 50 * '-'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoCTuwkGJZov"
   },
   "source": [
    "## Loading and Preprocessing Data\n",
    "Client records and notes from fictional clients of a nursing home are loaded, cleaned, and processed. The notes are grouped by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Vc3BWewlask",
    "outputId": "709a888f-543f-4c14-daab-a1dfb04d7983"
   },
   "outputs": [],
   "source": [
    "# Load dataset from Hugging Face and preprocess\n",
    "dataset = load_dataset(path_hf_records)\n",
    "df_records = dataset['train'].to_pandas()\n",
    "\n",
    "# Floor datetime to the first day of the month\n",
    "df_records['week'] = df_records['datetime'].dt.to_period('W').dt.to_timestamp()\n",
    "\n",
    "# Group records by 'client_id' and 'week', concatenating notes into one string\n",
    "df = (df_records\n",
    "    .dropna()\n",
    "    .assign(week=lambda df: pd.to_datetime(df['datetime']).dt.to_period('W').dt.to_timestamp()) # Add 'week' column\n",
    "    .groupby(['client_id', 'week'])\n",
    "    .agg({'note': lambda x: '\\n'.join(x)}) # Concatenate 'note' values\n",
    "    .reset_index()\n",
    "    .rename(columns={'note': 'weeknotes'})\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "  print(f\"Rows in original df: {df_records.shape[0]}, rows in processed df: {df.shape[0]}\\n\")\n",
    "  print(f\"SAMPLES{sep_line}\\n{df.sample(3)}\\n\")\n",
    "  print(f\"\\nContext column (weeknotes) example:{sep_line}\\n{df['weeknotes'].iloc[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMgbJRRcVB0x"
   },
   "source": [
    "## LLM Response Generation: Careplans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-qr-dif6cle"
   },
   "outputs": [],
   "source": [
    "class CarePlanItem(BaseModel):\n",
    "    problem: str = Field(..., description=\"Beschrijving van het zorgprobleem. Zorg dat er slechts één probleem wordt beschreven\")\n",
    "    care_goal: str = Field(..., description=\"Beschrijving van het zorgdoel\")\n",
    "    interventions: List[str] = Field(..., description=\"Beschrijving van 1 tot max 3 interventies\")\n",
    "\n",
    "class CarePlan(BaseModel):\n",
    "    careplan: List[CarePlanItem] = Field(..., description=\"Lijst van 1 tot max 3 zorgdoelen en interventies\")\n",
    "\n",
    "# Set up a parser to handle the output and inject instructions into the prompt template\n",
    "pyd_parser = PydanticOutputParser(pydantic_object=CarePlan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POwEfuzncjyx"
   },
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "Schrijf een zorgplan op basis van onderstaande rapportages.\n",
    "\n",
    "Belangrijk:\n",
    "- Gebruik uitsluitend informatie uit de rapportages. Voeg geen eigen interpretaties toe.\n",
    "- Richt je op algemene observaties en patronen, zonder de details van de rapportages over te nemen.\n",
    "\n",
    "---\n",
    "RAPPORTAGES:\n",
    "{rapportages}\n",
    "---\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"rapportages\"],\n",
    "    partial_variables={\"format_instructions\": pyd_parser.get_format_instructions()},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWTHsN8KYkIa",
    "outputId": "5b9e17e3-5096-49da-9870-abd7da031f08"
   },
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=open_ai_api_key,\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | pyd_parser\n",
    "\n",
    "\n",
    "if verbose:\n",
    "    sample_id = 5\n",
    "    sample_context = df['weeknotes'].iloc[sample_id]\n",
    "\n",
    "    sample_prompt = template.format(\n",
    "            rapportages=sample_context,\n",
    "            format_instructions=pyd_parser.get_format_instructions()\n",
    "    )\n",
    "\n",
    "    result = chain.invoke({\"rapportages\": sample_context})\n",
    "\n",
    "    # print the CarePlan\n",
    "    print(sample_prompt)\n",
    "\n",
    "    print(\"RESPONSE\")\n",
    "\n",
    "    for i, item in enumerate(result.careplan):\n",
    "        print(f\"Probleem {i+1}:\") #Added problem number\n",
    "        print(item.problem)\n",
    "        print(item.care_goal)\n",
    "        for intervention in item.interventions:\n",
    "            print(f\"- {intervention}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LzISH6fgctj",
    "outputId": "e0222c19-747f-4224-bac4-50afe5b968e2"
   },
   "outputs": [],
   "source": [
    "# Function to generate the Careplan\n",
    "def generate_careplan(notes: str) -> CarePlan:\n",
    "    try:\n",
    "        result = chain.invoke({\"rapportages\": notes})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Careplan: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the previously saved dataframe if it exists, otherwise start fresh\n",
    "if os.path.exists(fn_responses):\n",
    "    df = pd.read_pickle(fn_responses)\n",
    "else:\n",
    "    df['careplan_response'] = None  # Ensure the column exists\n",
    "\n",
    "# Create a callback instance to track cost\n",
    "with get_openai_callback() as cb:\n",
    "\n",
    "    # Generate Summaries, process only new entries\n",
    "    with tqdm(total=len(df), desc=\"Generating Careplans\") as pbar:  # Set the total for the progress bar\n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.isna(df.at[idx, 'careplan_response']):  # Process only new rows or missing responses\n",
    "                careplan = generate_careplan(row['weeknotes'])\n",
    "                df.at[idx, 'careplan_response'] = careplan\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Save progress every 100 iterations\n",
    "            if idx % 100 == 0:\n",
    "                df.to_pickle(fn_responses)\n",
    "                print(f\"Checkpoint saved at index {idx}, total cost so far: ${cb.total_cost:.4f}\")\n",
    "\n",
    "    # Save the final result\n",
    "    df.to_pickle(fn_responses)\n",
    "    print(\"Processing complete and final dataframe saved.\")\n",
    "    print(f\"Total cost: ${cb.total_cost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ow4eX46YVaQA"
   },
   "source": [
    "## Dataset Creation, Splitting and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Im19WrEnk3m"
   },
   "outputs": [],
   "source": [
    "instruction = '''Schrijf een zorgplan op basis van onderstaande rapportages. Gebruik alleen informatie uit de rapportages, zonder eigen interpretaties toe te voegen.\n",
    "\n",
    "Formatteer de output als een JSON-instantie die voldoet aan het onderstaande JSON-schema.\n",
    "```\n",
    "{”$defs”:{“CarePlanItem”:{“properties”:{“problem”:{“title”:“Problem”,“type”:“string”},“care_goal”:{“title”:“Care Goal”,“type”:“string”},“interventions”:{“title”:“Interventions”,“type”:“array”,“items”:{“type”:“string”}}},“required”:[“problem”,“care_goal”,“interventions”],“title”:“CarePlanItem”,“type”:“object”}},“properties”:{“careplan”:{“title”:“Careplan”,“type”:“array”,“items”:{”$ref”:”#/$defs/CarePlanItem”}}},“required”:[“careplan”]}\n",
    "```\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hO8uYRnKkVrT"
   },
   "outputs": [],
   "source": [
    "# use method chaining to rename columns and reorder\n",
    "df_careplan = (\n",
    "    df.rename(columns={'weeknotes': 'context', 'careplan_response': 'response'})\n",
    "    .assign(\n",
    "        response=lambda df: df['response'].astype(str),\n",
    "        instruction=instruction\n",
    "    )\n",
    "    [['client_id', 'week', 'context', 'instruction', 'response']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nK8bqFamVC1"
   },
   "outputs": [],
   "source": [
    "# Split the dataset and push to Hugging Face hub\n",
    "\n",
    "# Convert df to Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(\n",
    "    df=df_careplan,\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "# Split the dataset into training(80%), validation(10%), and test(10%) sets\n",
    "train_testvalid_split = dataset.train_test_split(\n",
    "    test_size=0.2,\n",
    "    seed=seed\n",
    ")\n",
    "test_valid_split = train_testvalid_split['test'].train_test_split(\n",
    "    test_size=0.5,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_testvalid_split['train'],\n",
    "    'validation': test_valid_split['train'],\n",
    "    'test': test_valid_split['test'],\n",
    "})\n",
    "\n",
    "# Push the dataset to Hugging Face Hub\n",
    "dataset_dict.push_to_hub(path_hf_careplan,\n",
    "                         commit_message=commit_message,\n",
    "                         private=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hW_DThatVF7D",
    "outputId": "33e98e06-1710-4857-b304-4f943d470cc2"
   },
   "outputs": [],
   "source": [
    "dataset_dict ['test'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0_QzokBtiya"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gcai_zuster_fietje",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
