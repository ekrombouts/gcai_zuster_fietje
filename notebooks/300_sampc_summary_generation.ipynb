{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/zuster_fietje/notebooks/300_zuster_fietje/100_sampc_summary_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwx-li06oX8C"
      },
      "source": [
        "# Summarisation: SAMPC\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:** 2024-09-16  \n",
        "\n",
        "### Description\n",
        "This notebook summarizes nursing home client notes into the SAMPC format using OpenAI’s GPT model via LangChain. It processes the data, generates summaries, and prepares the dataset by splitting it into training, validation, and test sets, and uploads it to the Hugging Face Hub for use in machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OOrSISU7r15"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q datasets langchain langchain_community langchain_openai\n",
        "\n",
        "# Import necessary modules\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "tK3FkZkElSxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQEKWDLNv1QJ"
      },
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "model = \"gpt-4o-mini-2024-07-18\"\n",
        "temperature = 0.3\n",
        "seed = 6\n",
        "path_hf_clientrecords = \"ekrombouts/Galaxy_records\"\n",
        "path_hf_sampc = \"ekrombouts/Galaxy_SAMPC\"\n",
        "commit_message = \"Grouped notes by week\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Preprocess the Dataset\n",
        "\n",
        "# Load dataset from Hugging Face\n",
        "dataset = load_dataset(path_hf_clientrecords)\n",
        "df_records = dataset['train'].to_pandas()\n",
        "\n",
        "# Floor datetime to the first day of the month\n",
        "df_records['week'] = df_records['datetime'].dt.to_period('W').dt.to_timestamp()\n",
        "\n",
        "# Group records by 'ct_id' and 'month', concatenating notes into one string\n",
        "df = (\n",
        "    df_records\n",
        "    .groupby(['ct_id', 'week'])\n",
        "    .agg({'note': lambda x: '\\n'.join(x)})\n",
        "    .reset_index()\n",
        "    .rename(columns={'note': 'notes'})\n",
        ")"
      ],
      "metadata": {
        "id": "0Vc3BWewlask"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SAMPC model using Pydantic to structure the summarised data\n",
        "class SAMPC(BaseModel):\n",
        "    somatiek: List[str] = Field(description=\"lichamelijke klachten\")\n",
        "    adl: str = Field(description=\"beschrijf welke hulp de cliënt nodig heeft bij wassen en kleden\")\n",
        "    mobiliteit: str = Field(description=\"beschrijf de mobiliteit (bv rolstoelafhankelijk, gebruik rollator, valgevaar)\")\n",
        "    continentie: str = Field(description=\"continentie\")\n",
        "    maatschappelijk: str = Field(description=\"beschrijf bijzonderheden familie en dagbesteding\")\n",
        "    psychisch: List[str] = Field(description=\"beschrijf cognitie en probleemgedrag\")"
      ],
      "metadata": {
        "id": "IOAyIZuCU4By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model and set up the Prompt Template\n",
        "\n",
        "# Initialize OpenAI Chat model\n",
        "model = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=temperature, model=model)\n",
        "\n",
        "# Set up a parser to handle the output and inject instructions into the prompt template\n",
        "pyd_parser = PydanticOutputParser(pydantic_object=SAMPC)\n",
        "\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Vat de onderstaande rapportages kort en bondig samen om een profiel van de cliënt te schetsen met de volgende categorieën:\n",
        "\n",
        "Categorieën:\n",
        "- Somatiek\n",
        "- Wassen en aankleden\n",
        "- Mobiliteit\n",
        "- Continentie\n",
        "- Maatschappelijk\n",
        "- Psychisch\n",
        "\n",
        "Belangrijk:\n",
        "- Gebruik uitsluitend informatie uit de rapportages. Voeg geen eigen interpretaties toe.\n",
        "- Als er geen informatie beschikbaar is voor een categorie, noteer dan 'geen informatie beschikbaar' voor die categorie.\n",
        "- Richt je op algemene observaties en patronen, zonder de details van de rapportages over te nemen.\n",
        "\n",
        "---\n",
        "RAPPORTAGES:\n",
        "{rapportages}\n",
        "---\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\",\n",
        "    input_variables=[\"rapportages\"],\n",
        "    partial_variables={\"format_instructions\": pyd_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "POwEfuzncjyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Chain and Define the Function to Generate Summaries\n",
        "\n",
        "# Initialize the chain\n",
        "chain = prompt_template | model | pyd_parser\n",
        "\n",
        "# Function to generate the SAMPC summary\n",
        "def generate_sampc_summary(notes: str) -> SAMPC:\n",
        "    result = chain.invoke({\"rapportages\": notes})\n",
        "    return result"
      ],
      "metadata": {
        "id": "9_navcQxdjgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Summaries\n",
        "sampc_results = []\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "  # Loop through the 'notes' column and generate SAMPC summaries, store them in the list\n",
        "  for notes in tqdm(df['notes'], desc=\"Generating SAMPC summaries\"):\n",
        "      sampc_summary = generate_sampc_summary(notes)\n",
        "      sampc_results.append(sampc_summary)\n",
        "  print(cb)"
      ],
      "metadata": {
        "id": "JapXTu8ofe-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to DataFrame and save\n",
        "df_sampc = pd.DataFrame([s.dict() for s in sampc_results])\n",
        "df_sampc['ct_id'] = df['ct_id']\n",
        "df_sampc['week'] = df['week']\n",
        "df_sampc['notes'] = df['notes']\n",
        "\n",
        "# Reorder columns\n",
        "df_sampc = df_sampc[['ct_id', 'week', 'notes', 'somatiek', 'adl', 'mobiliteit', 'continentie', 'maatschappelijk', 'psychisch']]"
      ],
      "metadata": {
        "id": "RLgJnSGyb9Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset and push to Hugging Face hub\n",
        "\n",
        "# Convert df to Hugging Face dataset\n",
        "dataset = Dataset.from_pandas(df_sampc)\n",
        "\n",
        "# Split the dataset into training(80%), validation(10%), and test(10%) sets\n",
        "train_testvalid_split = dataset.train_test_split(test_size=0.2, seed=seed)\n",
        "test_valid_split = train_testvalid_split['test'].train_test_split(test_size=0.5, seed=seed)\n",
        "\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_testvalid_split['train'],\n",
        "    'validation': test_valid_split['train'],\n",
        "    'test': test_valid_split['test'],\n",
        "})\n",
        "\n",
        "# Push the dataset to Hugging Face Hub\n",
        "dataset_dict.push_to_hub(path_hf_sampc,\n",
        "                         commit_message=commit_message,\n",
        "                         private=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "7nK8bqFamVC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0k4NzR3dbp6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "gcai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
