{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekrombouts/GenCareAI/blob/work_in_progress/scripts/instruct_model/100_create_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwx-li06oX8C"
      },
      "source": [
        "# Instruction prompts generation\n",
        "\n",
        "**Author:** Eva Rombouts  \n",
        "**Date:**   \n",
        "\n",
        "### Description\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The GenCareAIUtils package contains the class GenCareAISetup. GenCareAISetup detects the environment (Google Colab or local), handles file paths, and retrieves API keys. The package simplifies environment setup.\n",
        "!pip install GenCareAI\n",
        "from GenCareAI.GenCareAIUtils import GenCareAISetup\n",
        "\n",
        "setup = GenCareAISetup()\n",
        "\n",
        "if setup.environment == 'Colab':\n",
        "    !pip install -q datasets sentence-transformers langchain langchain_openai langchain_community\n",
        "\n",
        "verbose = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfaOMvwmPziM",
        "outputId": "8815e98a-81d8-48c3-febd-692c5b398afb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GenCareAI in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0OOrSISU7r15",
        "outputId": "86176dbb-41e1-498d-8fa2-511999f90aea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from tqdm.autonotebook import tqdm, trange\n",
        "from datasets import load_dataset, Dataset, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qQEKWDLNv1QJ"
      },
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "seed = 6\n",
        "path_hf_records = \"ekrombouts/Gardenia_records\"\n",
        "path_hf_clients = \"ekrombouts/Gardenia_clients\"\n",
        "path_hf_instruct = \"ekrombouts/Gardenia_instruct_dataset\"\n",
        "commit_message = \"Instruct dataset\"\n",
        "\n",
        "# File paths for saving/loading the embeddings\n",
        "fn_male_context_embeddings = setup.get_file_path('data/care_pal/male_context_embeddings.pt')\n",
        "fn_female_context_embeddings = setup.get_file_path('data/care_pal/female_context_embeddings.pt')\n",
        "fn_male_instruction_embeddings = setup.get_file_path('data/care_pal/male_instruction_embeddings.pt')\n",
        "fn_female_instruction_embeddings = setup.get_file_path('data/care_pal/female_instruction_embeddings.pt')\n",
        "fn_responses = setup.get_file_path('data/care_pal/context_instruction_pairs_with_responses.pkl')\n",
        "\n",
        "# Set additional parameters\n",
        "num_general_prompts = 250\n",
        "k_instructions=2\n",
        "k_contexts=50\n",
        "sep_line = 50*'-'\n",
        "\n",
        "# Set seed for reproducibility\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess data"
      ],
      "metadata": {
        "id": "DG6Elcx5YdSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets from Hugging Face and preprocess\n",
        "def load_and_preprocess_data():\n",
        "    dataset_records = load_dataset(path_hf_records)\n",
        "    dataset_clients = load_dataset(path_hf_clients)\n",
        "\n",
        "    df_records = dataset_records['train'].to_pandas()\n",
        "    df_clients = dataset_clients['train'].to_pandas()\n",
        "\n",
        "    def determine_client_gender(row):\n",
        "        name = row[\"name\"]\n",
        "        if \"Mevrouw\" in name:\n",
        "            return \"female\"\n",
        "        elif \"Meneer\" in name:\n",
        "            return \"male\"\n",
        "        else:\n",
        "            return \"unknown\"\n",
        "\n",
        "    df = (df_records\n",
        "          .dropna()\n",
        "          .assign(week=lambda df: pd.to_datetime(df['datetime']).dt.to_period('W').dt.to_timestamp())  # Add 'week' column\n",
        "          .groupby(['client_id', 'week'])\n",
        "          .agg({'note': lambda x: '\\n'.join(x)})  # Concatenate 'note' values\n",
        "          .reset_index()\n",
        "          .rename(columns={'note': 'weeknotes'})\n",
        "          .merge(df_clients[['client_id', 'name']], on='client_id', how='left')  # Merge with client name\n",
        "          .assign(gender=lambda df: df.apply(determine_client_gender, axis=1))  # Determine gender\n",
        "         )\n",
        "    return df, df_records\n",
        "\n",
        "df, df_records = load_and_preprocess_data()\n",
        "\n",
        "if verbose:\n",
        "  print(f\"Rows in original df: {df_records.shape[0]}, rows in processed df: {df.shape[0]}\\n\")\n",
        "  print(f\"SAMPLES{sep_line}\\n{df.sample(3)}\\n\")\n",
        "  print(f\"\\nContext column (weeknotes) example:{sep_line}\\n{df['weeknotes'].iloc[0]}\")\n",
        "  print(f\"\\nPercentage gender:{sep_line}\\n{df['gender'].value_counts(normalize=True)}\")\n",
        ""
      ],
      "metadata": {
        "id": "0Vc3BWewlask",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c204ec-e3df-4843-826c-aeec649e10ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows in original df: 28478, rows in processed df: 1681\n",
            "\n",
            "SAMPLES--------------------------------------------------\n",
            "    client_id       week                                          weeknotes  \\\n",
            "326    cro015 2022-12-12  Dhr. had vanmorgen moeite met het gebruik van ...   \n",
            "667    iri001 2023-02-06  Client reageerde niet goed op medicatie vanoch...   \n",
            "836    iri009 2022-10-17  Client had vanochtend moeite met opstaan en aa...   \n",
            "\n",
            "                        name gender  \n",
            "326        Meneer Gerrit Vos   male  \n",
            "667  Meneer Arnold den Bosch   male  \n",
            "836   Meneer Ferdinand Steen   male  \n",
            "\n",
            "\n",
            "Context column (weeknotes) example:--------------------------------------------------\n",
            "De cliënt is vandaag gearriveerd in het verpleeghuis. Hij is voorgesteld aan het personeel en de medebewoners. Het zorgplan is opgesteld en de benodigde hulp bij persoonlijke verzorging is gepland.\n",
            "Cliënt heeft hulp nodig gehad bij aankleden en eten. Hij kon korte afstanden lopen met behulp van een rollator.\n",
            "Cliënt leek wat verward en vergeetachtig in de avond. Extra observatie gedaan, gedrag goed in de gaten gehouden.\n",
            "Vandaag had de cliënt wat moeite met de lichamelijke verzorging. Rustig benaderd en ondersteund bij alle ADL-activiteiten.\n",
            "Cliënt had een afspraak met de fysiotherapeut voor mobiliteitsoefeningen. Oefeningen verliepen goed, verbetering zichtbaar.\n",
            "Cliënt kon vanavond zijn familie niet meer herkennen en was prikkelbaar. Gerustgesteld en afleiding geboden.\n",
            "De bloeddruk van de cliënt was vanochtend hoger dan normaal. Medicatie gegeven en bloeddruk opnieuw gecontroleerd.\n",
            "Cliënt had hulp nodig bij persoonlijke verzorging. Tijdens de zorgmomenten was hij rustiger dan gisteren.\n",
            "Cliënt had vandaag een goede eetlust en kon zelfstandig eten met wat hulp. Diabetescontrole uitgevoerd en bloedsuikerwaarden genoteerd.\n",
            "\n",
            "Percentage gender:--------------------------------------------------\n",
            "gender\n",
            "male      0.500892\n",
            "female    0.499108\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create instruction prompts"
      ],
      "metadata": {
        "id": "0X7X2lFyYRhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define instruction prompts for male, female, and general contexts\n",
        "instructions_male = [\n",
        "    \"Beschrijf lichamelijke klachten\",\n",
        "    \"Hoe voelt de patiënt zich?\",\n",
        "    \"Welke ziektes heeft cliënt?\",\n",
        "    \"Beschrijf de klachten van meneer\",\n",
        "    \"Heeft deze cliënt pijn?\",\n",
        "    \"Welke ongemakken ervaart dhr?\",\n",
        "    \"Welke behandeling is ingezet?\",\n",
        "    \"Beschrijf of er wonden of huidproblemen zijn\",\n",
        "    \"Beschrijf de benodigde ADL hulp\",\n",
        "    \"Beschrijf bijzonderheden over eten en drinken\",\n",
        "    \"Welke hulp heeft dhr nodig bij wassen en aankleden?\",\n",
        "    \"Geef aan welke hulp wordt geboden bij eten en drinken\",\n",
        "    \"Wordt meneer geholpen bij douchen?\",\n",
        "    \"Hoe wordt de ADL gedaan?\",\n",
        "    \"Beschrijf de mobiliteit van meneer\",\n",
        "    \"Welk loophulpmiddel gebruikt cliënt?\",\n",
        "    \"Beschrijf de mate van valgevaar\",\n",
        "    \"Welke hulp wordt geboden bij de mobiliteit?\",\n",
        "    \"Beschrijf de daginvulling van meneer\",\n",
        "    \"Doet ct mee aan activiteiten?\",\n",
        "    \"Hoe verlopen de nachten?\",\n",
        "    \"Heeft meneer lekker geslapen?\",\n",
        "    \"Geef aan of er stemmingsklachten zijn\",\n",
        "    \"Beschrijf gedragsproblemen\",\n",
        "    \"Hoe is de cognitie van meneer?\",\n",
        "]\n",
        "\n",
        "instructions_female = [\n",
        "    \"Beschrijf lichamelijke klachten\",\n",
        "    \"Hoe voelt de patiënt zich?\",\n",
        "    \"Welke ziektes heeft cliënte?\",\n",
        "    \"Beschrijf de klachten van mevrouw\",\n",
        "    \"Heeft deze cliënte pijn?\",\n",
        "    \"Welke ongemakken ervaart mw?\",\n",
        "    \"Welke behandeling is ingezet?\",\n",
        "    \"Beschrijf of er wonden of huidproblemen zijn\",\n",
        "    \"Beschrijf de benodigde ADL hulp\",\n",
        "    \"Beschrijf bijzonderheden over eten en drinken\",\n",
        "    \"Welke hulp heeft mw nodig bij wassen en aankleden?\",\n",
        "    \"Geef aan welke hulp wordt geboden bij eten en drinken\",\n",
        "    \"Wordt mevrouw geholpen bij douchen?\",\n",
        "    \"Hoe wordt de ADL gedaan?\",\n",
        "    \"Beschrijf de mobiliteit van mevrouw\",\n",
        "    \"Welk loophulpmiddel gebruikt cliënte?\",\n",
        "    \"Beschrijf de mate van valgevaar\",\n",
        "    \"Welke hulp wordt geboden bij de mobiliteit?\",\n",
        "    \"Beschrijf de daginvulling van mevrouw\",\n",
        "    \"Doet cte mee aan activiteiten?\",\n",
        "    \"Hoe verlopen de nachten?\",\n",
        "    \"Heeft mevrouw lekker geslapen?\",\n",
        "    \"Geef aan of er stemmingsklachten zijn\",\n",
        "    \"Beschrijf gedragsproblemen\",\n",
        "    \"Hoe is de cognitie van mevrouw?\",\n",
        "]\n",
        "\n",
        "instructions_general = [\n",
        "    \"Geef twee belangrijke punten waarop moet worden geobserveerd en gerapporteerd\",\n",
        "    \"Noem de aandachtspunten voor het zorgpersoneel\",\n",
        "    \"Welke acties moet het zorgteam nemen op basis van deze rapportages?\",\n",
        "    \"Vat de rapportages kort en bondig samen\",\n",
        "]\n",
        "\n",
        "# Combine all instruction prompts\n",
        "instructions = instructions_male + instructions_female + instructions_general\n",
        "\n",
        "if verbose:\n",
        "    print(f\"Number of male instructions: {len(instructions_male)}\")\n",
        "    print(f\"Number of female instructions: {len(instructions_female)}\")\n",
        "    print(f\"Number of general instructions: {len(instructions_general)}\")\n",
        "    print(f\"Total number of instructions: {len(instructions)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZuuYhAgc-SV",
        "outputId": "0ce8ac6c-f612-41d4-eec0-6daacff2a5be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of male instructions: 25\n",
            "Number of female instructions: 25\n",
            "Number of general instructions: 4\n",
            "Total number of instructions: 54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get contexts"
      ],
      "metadata": {
        "id": "fkot4uWTu0Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lists of contexts\n",
        "male_contexts = df[df['gender'] == 'male']['weeknotes'].tolist()\n",
        "female_contexts = df[df['gender'] == 'female']['weeknotes'].tolist()\n",
        "contexts = male_contexts + female_contexts\n",
        "\n",
        "if verbose:\n",
        "    print(f\"Number of male contexts: {len(male_contexts)}\")\n",
        "    print(f\"Number of female contexts: {len(female_contexts)}\")\n",
        "    print(f\"Total number of contexts: {len(contexts)}\")\n"
      ],
      "metadata": {
        "id": "e0A3R8atu72M",
        "outputId": "9434c98c-d1e9-4c4d-efa2-7a6b469d36b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of male contexts: 842\n",
            "Number of female contexts: 839\n",
            "Total number of contexts: 1681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load or Generate Embeddings"
      ],
      "metadata": {
        "id": "IA4_NaLw_OzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embeddings model\n",
        "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
        "\n",
        "# Function to load or generate embeddings\n",
        "def load_or_generate_embeddings(file_path, data, model):\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"Loading embeddings from {file_path}\")\n",
        "        embeddings = torch.load(file_path, weights_only=True)\n",
        "    else:\n",
        "        print(f\"Generating embeddings for {file_path}\")\n",
        "        embeddings = model.encode(\n",
        "            sentences=data,\n",
        "            convert_to_tensor=True,\n",
        "            show_progress_bar=True\n",
        "        )\n",
        "        torch.save(embeddings, file_path)\n",
        "    return embeddings\n",
        "\n",
        "# Load or generate embeddings for male and female contexts and instructions\n",
        "male_context_embeddings = load_or_generate_embeddings(fn_male_context_embeddings, male_contexts, model)\n",
        "female_context_embeddings = load_or_generate_embeddings(fn_female_context_embeddings, female_contexts, model)\n",
        "male_instruction_embeddings = load_or_generate_embeddings(fn_male_instruction_embeddings, instructions_male, model)\n",
        "female_instruction_embeddings = load_or_generate_embeddings(fn_female_instruction_embeddings, instructions_female, model)\n",
        "\n",
        "if verbose:\n",
        "    print(f\"\\nLength of male_context_embeddings: {len(male_context_embeddings)}\")\n",
        "    print(f\"\\nShape of the first embedding: {male_context_embeddings[0].shape}\")\n",
        "    print(f\"\\nFirst embedding:\\n{male_context_embeddings[0][:20]}...\")  # Only shows the first values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjqjRS7PDBLg",
        "outputId": "77bc2599-fabf-450b-98f6-10259b3d3db9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embeddings from /content/drive/My Drive/Colab Notebooks/GenCareAI/data/care_pal/male_context_embeddings.pt\n",
            "Loading embeddings from /content/drive/My Drive/Colab Notebooks/GenCareAI/data/care_pal/female_context_embeddings.pt\n",
            "Loading embeddings from /content/drive/My Drive/Colab Notebooks/GenCareAI/data/care_pal/male_instruction_embeddings.pt\n",
            "Loading embeddings from /content/drive/My Drive/Colab Notebooks/GenCareAI/data/care_pal/female_instruction_embeddings.pt\n",
            "\n",
            "Length of male_context_embeddings: 842\n",
            "\n",
            "Shape of the first embedding: torch.Size([512])\n",
            "\n",
            "First embedding:\n",
            "tensor([-0.0341, -0.0044, -0.0154,  0.0173,  0.0465,  0.0070, -0.0402, -0.0216,\n",
            "         0.0473,  0.0299, -0.0344,  0.0743,  0.0373, -0.0213, -0.0308,  0.0163,\n",
            "        -0.0564, -0.0126, -0.0306,  0.0160])...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculate Cosine Similarity and Process Pairs"
      ],
      "metadata": {
        "id": "yVgs7shlAU_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate top-k similarities\n",
        "def get_top_k_indices(cosine_sim_matrix, k, dim):\n",
        "    return torch.topk(torch.tensor(cosine_sim_matrix), k=k, dim=dim)\n",
        "\n",
        "def process_context_instruction_pairs(cosine_sim_matrix, contexts, instructions, k_instructions=2, k_contexts=50):\n",
        "    context_instruction_pairs = []\n",
        "\n",
        "    # Top K instructions per context\n",
        "    top_k_instructions_for_contexts = get_top_k_indices(cosine_sim_matrix, k=k_instructions, dim=1)\n",
        "\n",
        "    # Top K contexts per instruction\n",
        "    top_k_contexts_for_instructions = get_top_k_indices(cosine_sim_matrix, k=k_contexts, dim=0)\n",
        "\n",
        "    # Least fitting context per instruction\n",
        "    worst_contexts_for_instructions = torch.argmin(torch.tensor(cosine_sim_matrix), dim=0)\n",
        "\n",
        "    # Add top K instructions for each context\n",
        "    for i, top_instruction_indices in enumerate(top_k_instructions_for_contexts.indices):\n",
        "        for idx in top_instruction_indices:\n",
        "            context_instruction_pairs.append({\n",
        "                \"context\": contexts[i],\n",
        "                \"instruction\": instructions[idx.item()],\n",
        "                \"similarity\": cosine_sim_matrix[i, idx.item()],\n",
        "                \"relationship_type\": \"top instructions for context\"\n",
        "            })\n",
        "\n",
        "    # Add top K contexts for each instruction\n",
        "    for j, top_context_indices in enumerate(top_k_contexts_for_instructions.indices.T):\n",
        "        for idx in top_context_indices:\n",
        "            context_instruction_pairs.append({\n",
        "                \"context\": contexts[idx.item()],\n",
        "                \"instruction\": instructions[j],\n",
        "                \"similarity\": cosine_sim_matrix[idx.item(), j],\n",
        "                \"relationship_type\": \"top contexts for instruction\"\n",
        "            })\n",
        "\n",
        "    # Add least fitting context for each instruction\n",
        "    for j, worst_context_idx in enumerate(worst_contexts_for_instructions):\n",
        "        context_instruction_pairs.append({\n",
        "            \"context\": contexts[worst_context_idx.item()],\n",
        "            \"instruction\": instructions[j],\n",
        "            \"similarity\": cosine_sim_matrix[worst_context_idx.item(), j],\n",
        "            \"relationship_type\": \"worst context for instruction\"\n",
        "        })\n",
        "\n",
        "    return context_instruction_pairs"
      ],
      "metadata": {
        "id": "OP3rT08xiWo-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine male & female pairs"
      ],
      "metadata": {
        "id": "MSJViHhdV7jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process male and female datasets\n",
        "male_cosine_sim_matrix = cosine_similarity(male_context_embeddings, male_instruction_embeddings)\n",
        "female_cosine_sim_matrix = cosine_similarity(female_context_embeddings, female_instruction_embeddings)\n",
        "\n",
        "context_instruction_pairs_male = process_context_instruction_pairs(\n",
        "    cosine_sim_matrix=male_cosine_sim_matrix,\n",
        "    contexts=male_contexts, instructions=instructions_male,\n",
        "    k_instructions=k_instructions,\n",
        "    k_contexts=k_contexts\n",
        ")\n",
        "\n",
        "context_instruction_pairs_female = process_context_instruction_pairs(\n",
        "    cosine_sim_matrix=female_cosine_sim_matrix,\n",
        "    contexts=female_contexts,\n",
        "    instructions=instructions_female,\n",
        "    k_instructions=k_instructions,\n",
        "    k_contexts=k_contexts)\n",
        "\n",
        "# Combine male and female pairs\n",
        "context_instruction_pairs = context_instruction_pairs_male + context_instruction_pairs_female\n",
        "\n",
        "# Add general instructions to context-instruction pairs\n",
        "random.seed(seed)\n",
        "for instruction in instructions_general:\n",
        "    sampled_contexts = random.sample(contexts, num_general_prompts)\n",
        "    for context in sampled_contexts:\n",
        "        context_instruction_pairs.append({\n",
        "            \"context\": context,\n",
        "            \"instruction\": instruction,\n",
        "            \"similarity\": 0.0,\n",
        "            \"relationship_type\": \"general\"\n",
        "        })\n",
        "\n",
        "if verbose:\n",
        "    print(f\"Cosine similarity matrix shape - male: {male_cosine_sim_matrix.shape}\")\n",
        "    print(f\"Cosine similarity matrix shape - female: {female_cosine_sim_matrix.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN56nmeOibPH",
        "outputId": "1a34a56b-2a6f-46e1-9ddc-b915895c3413"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity matrix shape - male: (842, 25)\n",
            "Cosine similarity matrix shape - female: (839, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert context_instruction_pairs into a DataFrame\n",
        "df_context_instruction_pairs = pd.DataFrame(context_instruction_pairs)\n",
        "\n",
        "if verbose:\n",
        "    print(f\"SAMPLES\\n{df_context_instruction_pairs.sample(3)}\\n\")\n",
        "    print(\"INFO\")\n",
        "    print(df_context_instruction_pairs.info())\n",
        "    print(f\"\\nVALUE COUNTS\\n{df_context_instruction_pairs['instruction'].value_counts()}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEuMwTV7llZo",
        "outputId": "abf4d9e3-3959-4153-841f-cf07d4ae4f0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLES\n",
            "                                                context  \\\n",
            "1380  Cliënt maakte vanmorgen zelf grapjes en leek g...   \n",
            "40    Client vertoonde vanochtend agressief gedrag e...   \n",
            "2446  Cliënt kreeg vanmorgen frequente begeleiding b...   \n",
            "\n",
            "                               instruction  similarity  \\\n",
            "1380               Heeft deze cliënt pijn?    0.299746   \n",
            "40                 Heeft deze cliënt pijn?    0.280207   \n",
            "2446  Welk loophulpmiddel gebruikt cliënt?    0.195439   \n",
            "\n",
            "                 relationship_type  \n",
            "1380  top instructions for context  \n",
            "40    top instructions for context  \n",
            "2446  top contexts for instruction  \n",
            "\n",
            "INFO\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6912 entries, 0 to 6911\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   context            6912 non-null   object \n",
            " 1   instruction        6912 non-null   object \n",
            " 2   similarity         6912 non-null   float64\n",
            " 3   relationship_type  6912 non-null   object \n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 216.1+ KB\n",
            "None\n",
            "\n",
            "VALUE COUNTS\n",
            "instruction\n",
            "Hoe voelt de patiënt zich?                                                       442\n",
            "Welke hulp wordt geboden bij de mobiliteit?                                      353\n",
            "Wordt mevrouw geholpen bij douchen?                                              319\n",
            "Geef aan welke hulp wordt geboden bij eten en drinken                            317\n",
            "Beschrijf de benodigde ADL hulp                                                  317\n",
            "Beschrijf de daginvulling van mevrouw                                            291\n",
            "Welke ziektes heeft cliënt?                                                      266\n",
            "Welke acties moet het zorgteam nemen op basis van deze rapportages?              250\n",
            "Noem de aandachtspunten voor het zorgpersoneel                                   250\n",
            "Geef twee belangrijke punten waarop moet worden geobserveerd en gerapporteerd    250\n",
            "Vat de rapportages kort en bondig samen                                          250\n",
            "Heeft deze cliënt pijn?                                                          237\n",
            "Beschrijf de mobiliteit van mevrouw                                              217\n",
            "Welke ziektes heeft cliënte?                                                     206\n",
            "Welke behandeling is ingezet?                                                    203\n",
            "Beschrijf bijzonderheden over eten en drinken                                    190\n",
            "Beschrijf gedragsproblemen                                                       189\n",
            "Beschrijf de mobiliteit van meneer                                               180\n",
            "Heeft deze cliënte pijn?                                                         180\n",
            "Hoe wordt de ADL gedaan?                                                         167\n",
            "Beschrijf de klachten van mevrouw                                                150\n",
            "Beschrijf lichamelijke klachten                                                  138\n",
            "Wordt meneer geholpen bij douchen?                                               134\n",
            "Beschrijf of er wonden of huidproblemen zijn                                     109\n",
            "Welke hulp heeft dhr nodig bij wassen en aankleden?                              103\n",
            "Beschrijf de daginvulling van meneer                                             103\n",
            "Beschrijf de mate van valgevaar                                                  103\n",
            "Geef aan of er stemmingsklachten zijn                                            102\n",
            "Hoe verlopen de nachten?                                                         102\n",
            "Doet ct mee aan activiteiten?                                                    100\n",
            "Hoe is de cognitie van mevrouw?                                                   90\n",
            "Doet cte mee aan activiteiten?                                                    82\n",
            "Welke hulp heeft mw nodig bij wassen en aankleden?                                72\n",
            "Heeft mevrouw lekker geslapen?                                                    71\n",
            "Welk loophulpmiddel gebruikt cliënte?                                             60\n",
            "Welk loophulpmiddel gebruikt cliënt?                                              58\n",
            "Hoe is de cognitie van meneer?                                                    55\n",
            "Beschrijf de klachten van meneer                                                  52\n",
            "Heeft meneer lekker geslapen?                                                     52\n",
            "Welke ongemakken ervaart dhr?                                                     51\n",
            "Welke ongemakken ervaart mw?                                                      51\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates of columns 'context', 'instruction' en 'similarity'\n",
        "df_context_instruction_pairs = df_context_instruction_pairs.drop_duplicates(subset=['context', 'instruction', 'similarity'])\n",
        "\n",
        "if verbose:\n",
        "    print(f\"Num rows after dropping duplicates: {df_context_instruction_pairs.shape[0]}\\n\")\n",
        "    print(\"Info\")\n",
        "    print(df_context_instruction_pairs.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG4KkcOhmW90",
        "outputId": "926df70a-87aa-436c-ed30-d6ac108011ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num rows after dropping duplicates: 5725\n",
            "\n",
            "Info\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5725 entries, 0 to 6911\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   context            5725 non-null   object \n",
            " 1   instruction        5725 non-null   object \n",
            " 2   similarity         5725 non-null   float64\n",
            " 3   relationship_type  5725 non-null   object \n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 223.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(row):\n",
        "    return f\"\"\"Lees onderstaande rapportages, die een periode van een client in het verpleeghuis beschrijven, en beantwoord onderstaande instructie.\n",
        "Baseer je uitsluitend op de informatie die in de rapportages staat. Als er geen relevante informatie in staat, zeg dat dan. Hou je antwoord kort en bondig.\n",
        "\n",
        "RAPPORTAGES:\n",
        "{row['context']}\n",
        "\n",
        "INSTRUCTIE:\n",
        "{row['instruction']}\"\"\"\n",
        "\n",
        "df_context_instruction_pairs['prompt'] = df_context_instruction_pairs.apply(create_prompt, axis=1)\n",
        "\n",
        "if verbose:\n",
        "    print(f\"SAMPLES\\n{df_context_instruction_pairs.sample(3)}\\n\")\n",
        "    print(\"INFO\")\n",
        "    print(df_context_instruction_pairs.info())\n",
        "    print(f\"\\nPROMPT SAMPLE:\\n{df_context_instruction_pairs['prompt'].iloc[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfyviBtNmWjY",
        "outputId": "137de449-458f-4af8-b94e-1fcbd49e35dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLES\n",
            "                                               context  \\\n",
            "854  Cliënt had vannacht onrustige dromen en was da...   \n",
            "172  Meneer had vanochtend last van toenemende pijn...   \n",
            "185  Meneer had vanochtend moeite met opstaan uit b...   \n",
            "\n",
            "                                           instruction  similarity  \\\n",
            "854                    Beschrijf lichamelijke klachten    0.139319   \n",
            "172                            Heeft deze cliënt pijn?    0.205988   \n",
            "185  Geef aan welke hulp wordt geboden bij eten en ...    0.199888   \n",
            "\n",
            "                relationship_type  \\\n",
            "854  top instructions for context   \n",
            "172  top instructions for context   \n",
            "185  top instructions for context   \n",
            "\n",
            "                                                prompt  \n",
            "854  Lees onderstaande rapportages, die een periode...  \n",
            "172  Lees onderstaande rapportages, die een periode...  \n",
            "185  Lees onderstaande rapportages, die een periode...  \n",
            "\n",
            "INFO\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5725 entries, 0 to 6911\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   context            5725 non-null   object \n",
            " 1   instruction        5725 non-null   object \n",
            " 2   similarity         5725 non-null   float64\n",
            " 3   relationship_type  5725 non-null   object \n",
            " 4   prompt             5725 non-null   object \n",
            "dtypes: float64(1), object(4)\n",
            "memory usage: 268.4+ KB\n",
            "None\n",
            "\n",
            "PROMPT SAMPLE:\n",
            "Lees onderstaande rapportages, die een periode van een client in het verpleeghuis beschrijven, en beantwoord onderstaande instructie.\n",
            "Baseer je uitsluitend op de informatie die in de rapportages staat. Als er geen relevante informatie in staat, zeg dat dan. Hou je antwoord kort en bondig.\n",
            "\n",
            "RAPPORTAGES:\n",
            "De cliënt is vandaag gearriveerd in het verpleeghuis. Hij is voorgesteld aan het personeel en de medebewoners. Het zorgplan is opgesteld en de benodigde hulp bij persoonlijke verzorging is gepland.\n",
            "Cliënt heeft hulp nodig gehad bij aankleden en eten. Hij kon korte afstanden lopen met behulp van een rollator.\n",
            "Cliënt leek wat verward en vergeetachtig in de avond. Extra observatie gedaan, gedrag goed in de gaten gehouden.\n",
            "Vandaag had de cliënt wat moeite met de lichamelijke verzorging. Rustig benaderd en ondersteund bij alle ADL-activiteiten.\n",
            "Cliënt had een afspraak met de fysiotherapeut voor mobiliteitsoefeningen. Oefeningen verliepen goed, verbetering zichtbaar.\n",
            "Cliënt kon vanavond zijn familie niet meer herkennen en was prikkelbaar. Gerustgesteld en afleiding geboden.\n",
            "De bloeddruk van de cliënt was vanochtend hoger dan normaal. Medicatie gegeven en bloeddruk opnieuw gecontroleerd.\n",
            "Cliënt had hulp nodig bij persoonlijke verzorging. Tijdens de zorgmomenten was hij rustiger dan gisteren.\n",
            "Cliënt had vandaag een goede eetlust en kon zelfstandig eten met wat hulp. Diabetescontrole uitgevoerd en bloedsuikerwaarden genoteerd.\n",
            "\n",
            "INSTRUCTIE:\n",
            "Geef aan welke hulp wordt geboden bij eten en drinken\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Lees onderstaande rapportages, die een periode van een client in het verpleeghuis beschrijven, en beantwoord onderstaande instructie.\n",
        "Baseer je uitsluitend op de informatie die in de rapportages staat. Als er geen relevante informatie in staat, zeg dat dan. Hou je antwoord kort en bondig.\n",
        "\n",
        "RAPPORTAGES:\n",
        "{context}\n",
        "\n",
        "INSTRUCTIE:\n",
        "{instruction}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jIX1bg0nqnCd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"context\", \"instruction\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Initialize the language model with specified parameters\n",
        "llm = ChatOpenAI(\n",
        "    api_key=setup.get_openai_key(),\n",
        "    model=\"gpt-4o-mini-2024-07-18\",\n",
        "    # model=\"gpt-3.5-turbo-0125\",\n",
        "    temperature=0.3,\n",
        "    presence_penalty=0.2,\n",
        ")\n",
        "\n",
        "chain = prompt_template | llm\n",
        "\n"
      ],
      "metadata": {
        "id": "7LOKuYdbwf95"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if verbose:\n",
        "    sample_id = 50\n",
        "    sample_context = df_context_instruction_pairs['context'].iloc[sample_id]\n",
        "    sample_instruction = df_context_instruction_pairs['instruction'].iloc[sample_id]\n",
        "\n",
        "    sample_prompt = template.format(\n",
        "            context=sample_context,\n",
        "            instruction=sample_instruction\n",
        "    )\n",
        "\n",
        "    result = chain.invoke({\"context\": sample_context, \"instruction\": sample_instruction})\n",
        "\n",
        "    print(sample_prompt)\n",
        "    print(\"RELATIONSHIP TYPE\")\n",
        "    print(df_context_instruction_pairs['relationship_type'].iloc[sample_id])\n",
        "    print(\"RESPONSE\")\n",
        "    print(result.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NypIWqxRxBGK",
        "outputId": "0ca6b49e-7330-4c83-c264-87d10ef48ed0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lees onderstaande rapportages, die een periode van een client in het verpleeghuis beschrijven, en beantwoord onderstaande instructie.\n",
            "Baseer je uitsluitend op de informatie die in de rapportages staat. Als er geen relevante informatie in staat, zeg dat dan. Hou je antwoord kort en bondig.\n",
            "\n",
            "RAPPORTAGES:\n",
            "Cliënt is vanochtend rustig wakker geworden en heeft ontbeten in bed. Hij was emotioneel afstandelijk en reageerde niet veel op mijn vragen. Aanbod gedaan voor hulp bij persoonlijke verzorging, maar cliënt gaf aan het zelf te willen proberen.\n",
            "Tijdens de lunch had cliënt weinig eetlust en at maar een paar happen. Hierna liet hij weten moe te zijn en wilde rusten in bed. Geen tekenen van lichamelijk ongemak of pijn.\n",
            "Cliënt heeft vanmiddag wat tijd doorgebracht in de recreatiezaal, maar heeft voornamelijk naar buiten gestaard. Hij leek verdrietig en kwam niet tot interactie met andere bewoners. Geen fysiotherapie vandaag.\n",
            "Cliënt was vanmorgen vroeg wakker en voelde zich onrustig. Hij had last van zijn rug en wilde niet uit bed komen. Extra aandacht gegeven aan comfort en pijnverlichting.\n",
            "Tijdens de lunch heeft cliënt wat meer gegeten en leek iets opgewekter. Hij praatte kort met medebewoners, maar nog steeds weinig. Alert op eventuele tekenen van pijn door artritis.\n",
            "Cliënt heeft deelgenomen aan een luistermoment met muziek in de middag. Dit leek hem iets te kalmeren, maar al snel keerde hij terug naar zijn teruggetrokken houding. Geen opmerkelijke veranderingen in zijn gedrag.\n",
            "Vanochtend had cliënt moeite met opstaan en aankleden. Hij was emotioneel en wilde niet praten. Met geduld en ondersteuning heeft hij toch kunnen ontbijten en wassen.\n",
            "Cliënt at vandaag goed tijdens de lunch en leek meer geïnteresseerd in het gesprek aan tafel. Hij lachte kort naar een medebewoner, wat positief opviel.\n",
            "In de namiddag had cliënt last van vermoeidheid en vroeg om wat extra rust in zijn kamer. Hij keek wat voor zich uit en leek verdiept in gedachten. Geen veranderingen in mobiliteit.\n",
            "\n",
            "INSTRUCTIE:\n",
            "Heeft deze cliënt pijn?\n",
            "\n",
            "RELATIONSHIP TYPE\n",
            "top instructions for context\n",
            "RESPONSE\n",
            "Ja, de cliënt heeft pijn, met name last van zijn rug en er is alertheid op eventuele tekenen van pijn door artritis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the previously saved dataframe if it exists, otherwise start fresh\n",
        "if os.path.exists(fn_responses):\n",
        "    df_context_instruction_pairs = pd.read_pickle(fn_responses)\n",
        "else:\n",
        "    df_context_instruction_pairs['llm_response'] = None  # Ensure the column exists\n",
        "\n",
        "# Function to add LLM answer to the dataframe with error handling\n",
        "def get_llm_answer(row, cb):\n",
        "    try:\n",
        "        if pd.isna(row['llm_response']):  # Process only new prompts\n",
        "            result = chain.invoke({\"context\": row['context'], \"instruction\": row['instruction']}, callbacks=[cb])\n",
        "            return result.content\n",
        "        else:\n",
        "            return row['llm_response']  # Keep existing answers\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {row.name}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create a callback instance to track cost\n",
        "with get_openai_callback() as cb:\n",
        "\n",
        "    # Iterate over the rows and save progress intermittently\n",
        "    for idx, row in df_context_instruction_pairs.iterrows():\n",
        "        df_context_instruction_pairs.at[idx, 'llm_response'] = get_llm_answer(row, cb)\n",
        "\n",
        "        # Save progress every 10 iterations\n",
        "        if idx % 100 == 0:\n",
        "            df_context_instruction_pairs.to_pickle(fn_responses)\n",
        "            print(f\"Checkpoint saved at index {idx}, total cost so far: ${cb.total_cost:.4f}\")\n",
        "\n",
        "    # Save the final result\n",
        "    df_context_instruction_pairs.to_pickle(fn_responses)\n",
        "    print(\"Processing complete and final dataframe saved.\")\n",
        "    print(f\"Total cost: ${cb.total_cost:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN_H58ITyuQo",
        "outputId": "fa3cf4c8-e019-4ba4-849e-289fbf7fbc57"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved at index 0, total cost so far: $0.0000\n",
            "Checkpoint saved at index 100, total cost so far: $0.0000\n",
            "Checkpoint saved at index 200, total cost so far: $0.0000\n",
            "Checkpoint saved at index 300, total cost so far: $0.0000\n",
            "Checkpoint saved at index 400, total cost so far: $0.0000\n",
            "Checkpoint saved at index 500, total cost so far: $0.0000\n",
            "Checkpoint saved at index 600, total cost so far: $0.0000\n",
            "Checkpoint saved at index 700, total cost so far: $0.0000\n",
            "Checkpoint saved at index 800, total cost so far: $0.0000\n",
            "Checkpoint saved at index 900, total cost so far: $0.0000\n",
            "Checkpoint saved at index 1000, total cost so far: $0.0000\n",
            "Checkpoint saved at index 1100, total cost so far: $0.0000\n",
            "Checkpoint saved at index 1200, total cost so far: $0.0000\n",
            "Checkpoint saved at index 1300, total cost so far: $0.0000\n",
            "Checkpoint saved at index 1400, total cost so far: $0.0000\n",
            "Checkpoint saved at index 1500, total cost so far: $0.0000\n",
            "Checkpoint saved at index 1600, total cost so far: $0.0000\n",
            "Checkpoint saved at index 1700, total cost so far: $0.0000\n",
            "Checkpoint saved at index 2000, total cost so far: $0.0000\n",
            "Checkpoint saved at index 2500, total cost so far: $0.0000\n",
            "Checkpoint saved at index 2700, total cost so far: $0.0000\n",
            "Checkpoint saved at index 2800, total cost so far: $0.0000\n",
            "Checkpoint saved at index 2900, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3000, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3100, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3200, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3300, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3400, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3500, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3600, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3700, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3800, total cost so far: $0.0000\n",
            "Checkpoint saved at index 3900, total cost so far: $0.0000\n",
            "Checkpoint saved at index 4000, total cost so far: $0.0000\n",
            "Checkpoint saved at index 4100, total cost so far: $0.0000\n",
            "Checkpoint saved at index 4200, total cost so far: $0.0000\n",
            "Checkpoint saved at index 4300, total cost so far: $0.0000\n",
            "Checkpoint saved at index 4400, total cost so far: $0.0000\n",
            "Checkpoint saved at index 4500, total cost so far: $0.0000\n",
            "Checkpoint saved at index 4600, total cost so far: $0.0000\n",
            "Checkpoint saved at index 4900, total cost so far: $0.0000\n",
            "Checkpoint saved at index 5000, total cost so far: $0.0000\n",
            "Checkpoint saved at index 5100, total cost so far: $0.0000\n",
            "Checkpoint saved at index 5400, total cost so far: $0.0000\n",
            "Checkpoint saved at index 5700, total cost so far: $0.0000\n",
            "Checkpoint saved at index 5900, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6000, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6100, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6200, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6300, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6400, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6500, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6600, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6700, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6800, total cost so far: $0.0000\n",
            "Checkpoint saved at index 6900, total cost so far: $0.0000\n",
            "Processing complete and final dataframe saved.\n",
            "Total cost: $0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_ct = 63\n",
        "print(df_context_instruction_pairs['prompt'].iloc[example_ct])\n",
        "print(\"\\nRESPONSE:\")\n",
        "print(df_context_instruction_pairs['llm_response'].iloc[example_ct])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THBYapq8g4gh",
        "outputId": "1ff6d6da-7a18-4e2b-9a35-9893e283b3d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lees onderstaande rapportages, die een periode van een client in het verpleeghuis beschrijven, en beantwoord onderstaande instructie.\n",
            "Baseer je uitsluitend op de informatie die in de rapportages staat. Als er geen relevante informatie in staat, zeg dat dan. Hou je antwoord kort en bondig.\n",
            "\n",
            "RAPPORTAGES:\n",
            "De mentale toestand van de cliënt lijkt stabiel. Morgenactiviteiten aangepast om hem meer te betrekken bij het groepsgebeuren.\n",
            "Het gewichtsverlies blijft een zorg. Psycholoog ingeschakeld om te praten over mogelijke onderliggende oorzaken van eetproblemen.\n",
            "Cliënt huilt vanavond bij het naar bed gaan. Troost geboden en rustgevende muziek afgespeeld om te helpen bij het kalmeren.\n",
            "De cliënt lijkt vandaag wat meer alert te zijn en toont interesse in de activiteiten. Stimulatie van zintuigen ingevoerd om cognitie te bevorderen.\n",
            "Gewichtsverlies blijft een probleem, ondanks alle inspanningen. Diëtist werkt aan een persoonlijk voedingsplan om de calorie-inname te verhogen.\n",
            "Cliënt lijkt vanavond te genieten van interactie met medewerkers. Extra tijd genomen voor persoonlijke gesprekken en aandacht.\n",
            "Vandaag lijkt de cliënt minder verward en meer aanwezig te zijn. Aangepaste dagplanning om de goede momenten te benutten.\n",
            "Gewichtsverlies nog steeds een probleem. Familie geïnformeerd over de situatie en gevraagd om ondersteuning bij de maaltijden.\n",
            "Cliënt lijkt vanavond te genieten van een muziektherapiesessie. Kalmerende effecten opgemerkt na deelname aan de sessie.\n",
            "Dhr. had vandaag moeite met het draaien in bed vanwege rugpijn. Extra aandacht besteed aan huidverzorging.\n",
            "Beginnende decubitusplek geconstateerd op de huid van dhr. Zorgverleners gestart met specifieke behandeling voor decubituspreventie.\n",
            "Dhr. vertoont tekenen van ongemak vanwege de decubitusplek. Zorg verleend om pijn te verlichten en comfort te bieden.\n",
            "Vandaag extra aandacht besteed aan lichamelijke mobiliteit en huidverzorging bij dhr. Hulp ingeroepen van fysiotherapeut voor mobiliteitsoefeningen.\n",
            "Decubitusplek van dhr. lijkt zich te stabiliseren na specifieke zorg. Controle uitgevoerd en aangepaste behandeling voortgezet.\n",
            "Dhr. reageert positief op de zorginterventies. Huidverzorging en draaien in bed procedure verlopen soepel.\n",
            "Dhr. is vanochtend rusteloos en lijkt meer verward dan normaal. Extra observatie en begeleiding geboden door zorgteam.\n",
            "Desoriëntatie en teruggetrokken gedrag bij dhr. opgemerkt. Overleg gevoerd met psycholoog voor gepaste interventies.\n",
            "Dhr. heeft zich in de middag wat meer opengesteld en lijkt minder in zichzelf gekeerd. Afleidende activiteiten om betrokkenheid te vergroten.\n",
            "Terugkerende rugpijn bij dhr. Leuningen van rolstoel aangepast voor meer stabiliteit en comfort.\n",
            "Decubitusplek vertoont tekenen van genezing. Zorgplan geëvalueerd en aangepast op basis van de verbetering.\n",
            "Dhr. heeft vandaag goed gereageerd op de zorginterventies. Huidverzorging routine verloopt goed zonder complicaties.\n",
            "\n",
            "INSTRUCTIE:\n",
            "Hoe voelt de patiënt zich?\n",
            "\n",
            "RESPONSE:\n",
            "De patiënt vertoont een wisselend emotioneel welzijn. Hij lijkt momenten van alertheid en betrokkenheid te hebben, maar ervaart ook verdriet, verwardheid en ongemak. Er zijn momenten van genieten, zoals tijdens muziektherapie, maar ook momenten van rusteloosheid en desoriëntatie. Gewichtsverlies en fysieke ongemakken, zoals rugpijn en decubitus, dragen bij aan zijn algehele toestand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = (df_context_instruction_pairs\n",
        "      .loc[:, ['context', 'instruction', 'llm_response']]\n",
        "      .rename(columns={'llm_response': 'response'})\n",
        "     )\n",
        "\n",
        "dataset = Dataset.from_pandas(\n",
        "    df=df,\n",
        "    preserve_index=False\n",
        ")\n",
        "\n",
        "# Split the dataset into training and test/validation splits\n",
        "train_testvalid_split = dataset.train_test_split(test_size=0.2, seed=seed)\n",
        "\n",
        "# Further split the test set into validation and test sets\n",
        "test_valid_split = train_testvalid_split['test'].train_test_split(test_size=0.5, seed=seed)\n",
        "\n",
        "# Create a DatasetDict object to hold the splits\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_testvalid_split['train'],\n",
        "    'validation': test_valid_split['train'],\n",
        "    'test': test_valid_split['test'],\n",
        "})\n",
        "\n",
        "# # Push the dataset to HuggingFace Hub with the specified path and commit message\n",
        "# dataset_dict.push_to_hub(path_hf_instruct,\n",
        "#                          commit_message=commit_message,\n",
        "#                          private=True)"
      ],
      "metadata": {
        "id": "Vkm-jb-1Y5SZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lIysUnOGkQxL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "gcai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}